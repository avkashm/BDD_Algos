{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class node(object):\n",
    "    \n",
    "    def __init__(self,state):\n",
    "        self.state=state\n",
    "        self.inbound={}\n",
    "        self.outbound={}\n",
    "        self.cost=0\n",
    "        \n",
    "    def __str__(self):\n",
    "        string=\"State: \"+str(self.state)\n",
    "        return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sensitivity=10\n",
    "W_sensitivity=40\n",
    "\n",
    "c_rand=[10,8,5,8,7,3,4,4,2,4]\n",
    "w_rand=[8,6,10,9,9,2,8,10,7,4]\n",
    "\n",
    "c_w_asc=[3,4,8,2,10,4,8,7,5,4]\n",
    "w_w_asc=[2,4,6,7,8,8,9,9,10,10]\n",
    "\n",
    "c_w_des=c_w_asc[::-1]\n",
    "w_w_des=w_w_asc[::-1]\n",
    "\n",
    "c_c_asc=[2,3,4,4,4,5,7,8,8,10]\n",
    "w_c_asc=[7,2,4,8,10,10,9,6,9,8]\n",
    "\n",
    "c_c_des=c_c_asc[::-1]\n",
    "w_c_des=w_c_asc[::-1]\n",
    "\n",
    "c_r_asc=[2,4,4,5,7,8,4,10,8,3]\n",
    "w_r_asc=[7,10,8,10,9,9,4,8,6,2]\n",
    "\n",
    "c_r_des=c_r_asc[::-1]\n",
    "w_r_des=w_r_asc[::-1]\n",
    "\n",
    "c_testset=[c_rand,c_w_asc,c_w_des,c_c_asc,c_c_des,c_r_asc,c_r_des]\n",
    "w_testset=[w_rand,w_w_asc,w_w_des,w_c_asc,w_c_des,w_r_asc,w_r_des]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_sensitivity=20\n",
    "# W_sensitivity=80\n",
    "\n",
    "# c_rand=[7,7,2,10,10,2,3,10,7,3,5,8,9,10,4,3,9,10,9,1]\n",
    "# w_rand=[6,9,8,3,8,6,10,5,9,4,6,8,3,7,10,8,4,10,6,10]\n",
    "\n",
    "# c_w_asc=[10,9,3,9,10,7,2,5,9,10,2,10,8,3,7,7,3,4,10,1]\n",
    "# w_w_asc=[3,3,4,4,5,6,6,6,6,7,8,8,8,8,9,9,10,10,10,10]\n",
    "\n",
    "# c_w_des=c_w_asc[::-1]\n",
    "# w_w_des=w_w_asc[::-1]\n",
    "\n",
    "# c_c_asc=[1,2,2,3,3,3,4,5,7,7,7,8,9,9,9,10,10,10,10,10]\n",
    "# w_c_asc=[10,8,6,10,8,4,10,6,9,9,6,8,6,4,3,10,8,7,5,3]\n",
    "\n",
    "# c_c_des=c_c_asc[::-1]\n",
    "# w_c_des=w_c_asc[::-1]\n",
    "\n",
    "# c_r_asc=[1,2,3,2,3,4,3,7,7,5,8,10,7,10,10,9,10,9,9,10]\n",
    "# w_r_asc=[10,8,10,6,8,10,4,9,9,6,8,10,6,8,7,6,5,4,3,3]\n",
    "\n",
    "# c_r_des=c_r_asc[::-1]\n",
    "# w_r_des=w_r_asc[::-1]\n",
    "\n",
    "# c_testset=[c_rand,c_w_asc,c_w_des,c_c_asc,c_c_des,c_r_asc,c_r_des]\n",
    "# w_testset=[w_rand,w_w_asc,w_w_des,w_c_asc,w_c_des,w_r_asc,w_r_des]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 4, 8, 7, 10, 4, 2, 8, 4, 3]\n",
      "[10 10  9  9  8  8  7  6  4  2]\n",
      "c: 3 w: 2\n",
      "c: 4 w: 4\n",
      "c: 8 w: 6\n",
      "c: 2 w: 7\n",
      "c: 10 w: 8\n",
      "c: 4 w: 8\n",
      "c: 8 w: 9\n",
      "c: 7 w: 9\n",
      "c: 5 w: 10\n",
      "c: 4 w: 10\n"
     ]
    }
   ],
   "source": [
    "c_test=[x for _,x in sorted(zip(w_rand,c_rand))][::-1]\n",
    "w_test=np.sort(w_rand)[::-1]\n",
    "print(c_test)\n",
    "print(w_test)\n",
    "for i in range(len(w_rand)):\n",
    "    print(\"c: {} w: {}\".format(c_w_asc[i],w_w_asc[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Algorithm_1(n,cvals,wvals,W):\n",
    "    \n",
    "    #All layers is the tree containing each layer\n",
    "    #All_layers keys are the layer numbers\n",
    "    #Make root node before beginning\n",
    "    all_layers={}\n",
    "    all_layers[0]={}\n",
    "    all_layers[0][0]=node(0)\n",
    "    \n",
    "    #Iterate through each layer\n",
    "    for x in range(1,n):\n",
    "        #Create next layer\n",
    "        currLayer=all_layers[x-1]\n",
    "        all_layers[x]={}\n",
    "        nextLayer=all_layers[x]\n",
    "        \n",
    "        #Initialize layer variables\n",
    "        #Saves having to compute this for each node in the layer\n",
    "        w_current=wvals[x-1]\n",
    "        c_current=cvals[x-1]\n",
    "        \n",
    "        #Begin with the 0 decision: deciding not to take the item\n",
    "        #Node weight remains the same, so create new node in the subsequent layer\n",
    "        #Direct arcs to new node\n",
    "        for nodeInstance in currLayer.values():\n",
    "            new_node=node(nodeInstance.state)\n",
    "            nextLayer[nodeInstance.state]=new_node\n",
    "            nodeInstance.outbound[0]=new_node\n",
    "            new_node.inbound[0]=nodeInstance\n",
    "        \n",
    "        #Next do the 1 decision: deciding to take the item\n",
    "        for nodeInstance in currLayer.values():\n",
    "            newstate=nodeInstance.state+w_current\n",
    "            #Feasability check\n",
    "            if newstate<=W:\n",
    "                #Check if the new state already exists in the subsequent layer\n",
    "                if nextLayer.get(newstate):\n",
    "                    #Add arc into node inbound and outbound\n",
    "                    nodeInstance.outbound[c_current]=nextLayer[newstate]\n",
    "                    nextLayer[newstate].inbound[c_current]=nodeInstance\n",
    "                else:\n",
    "                    #Create new node\n",
    "                    new_node=node(newstate)\n",
    "                    nextLayer[newstate]=new_node\n",
    "                    #Add arc to node inbound and outbound\n",
    "                    nodeInstance.outbound[c_current]=new_node\n",
    "                    new_node.inbound[c_current]=nodeInstance\n",
    "                        \n",
    "    #Changed from W because Rachel said so\n",
    "    terminal_node=node(-1)\n",
    "    all_layers[n]={}\n",
    "    all_layers[n][-1]=terminal_node\n",
    "    \n",
    "    w_final=wvals[n-1]\n",
    "    c_final=cvals[n-1]\n",
    "    \n",
    "    #Swap arc dictionary keys and values\n",
    "    #This method still leads to probelms in the inbound nodes as you can have multiple inbound arc costs\n",
    "    #But hey, it works for outbound\n",
    "    \n",
    "    #Final layer 0 decision\n",
    "    for nodeInstance in all_layers[n-1].values():\n",
    "        \n",
    "        nodeInstance.outbound[0]=terminal_node\n",
    "        terminal_node.inbound[0]=nodeInstance\n",
    "    \n",
    "    #Final layer 1 decision\n",
    "    for nodeInstance in all_layers[n-1].values():\n",
    "        \n",
    "        if nodeInstance.state+w_final<=W:\n",
    "            nodeInstance.outbound[c_final]=terminal_node\n",
    "            terminal_node.inbound[c_final]=nodeInstance\n",
    "            \n",
    "    return all_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Algorithm_2(reduced_layers,n):\n",
    "    #Final reduction algorithm here we go\n",
    "    #Starting from the second last layer moving up\n",
    "    for x in range(n-1,0,-1):\n",
    "        to_remove={}\n",
    "        tail_list={}\n",
    "        for nodeInstance in reduced_layers[x].values():\n",
    "            #Add ending combination if not already in the tail list\n",
    "            current_tuple=tuple(nodeInstance.outbound.items())\n",
    "            \n",
    "            #If ending combination exists\n",
    "            if tail_list.get(current_tuple):\n",
    "                to_remove[nodeInstance.state]=nodeInstance\n",
    "                #Redirect arcs\n",
    "                for arcCost, comingFrom in nodeInstance.inbound.items():\n",
    "                    tail_list[current_tuple].inbound[arcCost]=comingFrom\n",
    "                    comingFrom.outbound[arcCost]=tail_list[current_tuple]\n",
    "                    \n",
    "                    #Remove arcs from comingFrom node\n",
    "                    if comingFrom.outbound.get(nodeInstance):\n",
    "                        del(comingFrom.outbound[nodeInstance])\n",
    "            \n",
    "            #If ending combination does not exist\n",
    "            else:\n",
    "                tail_list[current_tuple]=nodeInstance\n",
    "                        \n",
    "        #Remove all duplicate nodes            \n",
    "        for remove_node in to_remove.values():\n",
    "            del(reduced_layers[x][remove_node.state])\n",
    "            remove_node=None\n",
    "        \n",
    "    return reduced_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Longest_Path(reduced_layers,cvals):\n",
    "    #Initiate final score and trail list\n",
    "    n=len(reduced_layers)-1\n",
    "    final_score=0\n",
    "    trail=[0]*(len(reduced_layers)-1)\n",
    "    \n",
    "    #Iterate through every node and incoming arc, update highest cost found\n",
    "    for layer in reduced_layers.values():\n",
    "        for nodeInstance in layer.values():\n",
    "            for arcCost, goingTo in nodeInstance.outbound.items():\n",
    "                #Only update arcs where cost > 0\n",
    "                if (nodeInstance.cost+arcCost)>goingTo.cost:\n",
    "                    goingTo.cost=nodeInstance.cost+arcCost\n",
    "                    \n",
    "    #In the last layer of nodes find the node with the largest cost and set it as the final score\n",
    "    for nodeInstance in reduced_layers[n].values():\n",
    "        final_score=nodeInstance.cost\n",
    "        break\n",
    "    \n",
    "    #Initialize traceback score (optima value), and track node progress\n",
    "    traceback=final_score\n",
    "    current_node=reduced_layers[n][-1]\n",
    "    \n",
    "    for x in range(n,0,-1):\n",
    "        \n",
    "        #Iterate through all layers to find current node\n",
    "        #Possibly reduce solve time even further by only tracing back through current_node\n",
    "        #Keep track of when current_node is contained in the root layer\n",
    "        #If so, you've reached the top\n",
    "        \n",
    "        previous_layer=reduced_layers.get(x-1)\n",
    "        c_current=cvals[x-1]\n",
    "        target=traceback-c_current\n",
    "        \n",
    "        #Iterate through each node\n",
    "        for nodeInstance in previous_layer.values():\n",
    "            \n",
    "            #If take item is an option, do it\n",
    "            if nodeInstance.cost==target:\n",
    "                #Ensure that the node is along the same trail as lower levels\n",
    "                if nodeInstance.outbound.get(c_current) is current_node:\n",
    "                    #Update trail, current node, and traceback\n",
    "                    trail[x-1]=1\n",
    "                    current_node=nodeInstance\n",
    "                    traceback-=c_current\n",
    "                    break\n",
    "            \n",
    "            #If don't take is an option, do it as well\n",
    "            elif nodeInstance.cost==traceback:\n",
    "                #Update current node\n",
    "                if nodeInstance.outbound.get(0) is current_node:\n",
    "                    current_node=nodeInstance\n",
    "                    break\n",
    "    \n",
    "            \n",
    "    return final_score, trail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Max_Width(all_layers):\n",
    "    \n",
    "    max_width=0\n",
    "    node_count=0\n",
    "    \n",
    "    for layer in all_layers.values():\n",
    "        no_of_nodes=len(layer)\n",
    "        node_count+=no_of_nodes\n",
    "        if no_of_nodes>max_width:\n",
    "            max_width=no_of_nodes\n",
    "            \n",
    "    return max_width, node_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Arc_Count(all_layers):\n",
    "    \n",
    "    arc_count=0\n",
    "    \n",
    "    for layer in all_layers.values():\n",
    "        for nodeInstance in layer.values():\n",
    "            arc_count+=len(nodeInstance.outbound)\n",
    "    \n",
    "    return arc_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Order_Testing():\n",
    "    #Initialize testing varibales\n",
    "    testset=[n_sensitivity,W_sensitivity]\n",
    "\n",
    "    for nono in range(0,7):\n",
    "        #Build BDD tree and solve\n",
    "        start1=time.perf_counter()\n",
    "        all_layers=Algorithm_1(testset[0],c_testset[nono],w_testset[nono],testset[1])\n",
    "        [full_finalScore,full_trail]=Longest_Path(all_layers,c_testset[nono])\n",
    "        [all_width, all_nodeCount]=Max_Width(all_layers)\n",
    "        all_arcCount=Arc_Count(all_layers)\n",
    "        end1=time.perf_counter()\n",
    "\n",
    "        #Reduce BDD and solve\n",
    "        start2=time.perf_counter()\n",
    "        reduced_layers=Algorithm_2(all_layers,testset[0])\n",
    "        [reduced_finalScore,reduced_trail]=Longest_Path(reduced_layers,c_testset[nono])\n",
    "        [reduced_width, reduced_nodeCount]=Max_Width(reduced_layers)\n",
    "        reduced_arcCount=Arc_Count(reduced_layers)\n",
    "        end2=time.perf_counter()\n",
    "\n",
    "        print(\"Test no. {}\\n\".format(nono+1))\n",
    "        print(\"Full BDD number of nodes: {}\".format(all_nodeCount))\n",
    "        print(\"Reduced BDD number of nodes: {}\".format(reduced_nodeCount))\n",
    "        print(\"Full BDD number of arcs: {}\".format(all_arcCount))\n",
    "        print(\"Reduced BDD number of arcs: {}\".format(reduced_arcCount))\n",
    "        print(\"Full BDD max width: {}\".format(all_width))\n",
    "        print(\"Reduced BDD max width: {}\\n\".format(reduced_width))\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Order \n",
      "\n",
      "1: Random\n",
      "2: w ascending\n",
      "3: w descending\n",
      "4: c ascending\n",
      "5: c descending\n",
      "6: ratio ascending\n",
      "7: ratio descending\n",
      "\n",
      "\n",
      "Test no. 1\n",
      "\n",
      "Full BDD number of nodes: 189\n",
      "Reduced BDD number of nodes: 78\n",
      "Full BDD number of arcs: 350\n",
      "Reduced BDD number of arcs: 144\n",
      "Full BDD max width: 37\n",
      "Reduced BDD max width: 17\n",
      "\n",
      "Test no. 2\n",
      "\n",
      "Full BDD number of nodes: 194\n",
      "Reduced BDD number of nodes: 52\n",
      "Full BDD number of arcs: 356\n",
      "Reduced BDD number of arcs: 98\n",
      "Full BDD max width: 38\n",
      "Reduced BDD max width: 10\n",
      "\n",
      "Test no. 3\n",
      "\n",
      "Full BDD number of nodes: 152\n",
      "Reduced BDD number of nodes: 52\n",
      "Full BDD number of arcs: 283\n",
      "Reduced BDD number of arcs: 91\n",
      "Full BDD max width: 37\n",
      "Reduced BDD max width: 10\n",
      "\n",
      "Test no. 4\n",
      "\n",
      "Full BDD number of nodes: 207\n",
      "Reduced BDD number of nodes: 72\n",
      "Full BDD number of arcs: 382\n",
      "Reduced BDD number of arcs: 134\n",
      "Full BDD max width: 38\n",
      "Reduced BDD max width: 17\n",
      "\n",
      "Test no. 5\n",
      "\n",
      "Full BDD number of nodes: 176\n",
      "Reduced BDD number of nodes: 72\n",
      "Full BDD number of arcs: 327\n",
      "Reduced BDD number of arcs: 129\n",
      "Full BDD max width: 37\n",
      "Reduced BDD max width: 17\n",
      "\n",
      "Test no. 6\n",
      "\n",
      "Full BDD number of nodes: 181\n",
      "Reduced BDD number of nodes: 62\n",
      "Full BDD number of arcs: 337\n",
      "Reduced BDD number of arcs: 111\n",
      "Full BDD max width: 37\n",
      "Reduced BDD max width: 14\n",
      "\n",
      "Test no. 7\n",
      "\n",
      "Full BDD number of nodes: 190\n",
      "Reduced BDD number of nodes: 62\n",
      "Full BDD number of arcs: 349\n",
      "Reduced BDD number of arcs: 115\n",
      "Full BDD max width: 37\n",
      "Reduced BDD max width: 14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing Order \\n\")\n",
    "print(\"1: Random\")\n",
    "print(\"2: w ascending\")\n",
    "print(\"3: w descending\")\n",
    "print(\"4: c ascending\")\n",
    "print(\"5: c descending\")\n",
    "print(\"6: ratio ascending\")\n",
    "print(\"7: ratio descending\\n\\n\")\n",
    "\n",
    "Order_Testing()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
